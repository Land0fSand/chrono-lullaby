# -*- coding: utf-8 -*-
import yt_dlp
import os
import datetime
import json
import sys
import time
import logging
import re
import copy
from typing import Optional

# è®¾ç½®é»˜è®¤ç¼–ç ä¸ºUTF-8
if sys.stdout.encoding != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')
if sys.stderr.encoding != 'utf-8':
    sys.stderr.reconfigure(encoding='utf-8')

from config import (
    AUDIO_FOLDER,
    DOWNLOAD_ARCHIVE,
    DEBUG_INFO,
    STORY_FILE,
    COOKIES_FILE,
    get_video_delay_min,
    get_video_delay_max,
    get_filter_days,
    get_max_videos_per_channel,
    get_config_provider,
)
from logger import get_logger, log_with_context, TRACE_LEVEL
from pathlib import Path
import random
# ä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—ç³»ç»Ÿ
logger = get_logger('downloader.dl_audio')

_download_archive_cache = {
    "mtime": None,
    "entries": set(),
}

_cleaned_audio_folders = set()


def cleanup_incomplete_downloads(folder: str) -> int:
    """
    åˆ é™¤éŸ³é¢‘ç›®å½•ä¸­æ®‹ç•™çš„ .tmp/.part ç­‰æœªå®Œæˆä¸‹è½½æ–‡ä»¶ï¼Œé¿å…ä¸‹æ¬¡ç»§ç»­ä¸‹è½½æŠ¥ 416ã€‚
    åŒä¸€ä¸ªç›®å½•åªåœ¨è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸå†…æ¸…ç†ä¸€æ¬¡ï¼Œé˜²æ­¢é‡å¤æ—¥å¿—ã€‚
    """
    if not folder:
        return 0
    abs_folder = os.path.abspath(folder)
    if abs_folder in _cleaned_audio_folders:
        return 0
    path = Path(abs_folder)
    if not path.exists():
        return 0

    removed = 0
    for entry in path.iterdir():
        if not entry.is_file():
            continue
        name = entry.name
        if (
            name.endswith('.tmp')
            or '.tmp.' in name
            or name.endswith('.part')
            or name.endswith('.ytdl')
        ):
            try:
                entry.unlink()
                removed += 1
            except OSError:
                continue

    if removed:
        log_with_context(
            logger, logging.INFO,
            "ğŸ§¹ æ¸…ç†æœªå®Œæˆçš„ä¸‹è½½æ®‹ç•™",
            audio_folder=abs_folder,
            removed_files=removed
        )

    _cleaned_audio_folders.add(abs_folder)
    return removed


def cleanup_partial_files_for_base(base_path: str) -> int:
    """
    åˆ é™¤æŸä¸ªè§†é¢‘å¯¹åº”çš„æ®‹ç•™ .tmp/.part æ–‡ä»¶ã€‚
    """
    if not base_path:
        return 0
    path = Path(base_path)
    parent = path.parent
    if not parent.exists():
        return 0
    prefix = path.name
    removed = 0
    for entry in parent.iterdir():
        if not entry.is_file():
            continue
        name = entry.name
        if not name.startswith(prefix):
            continue
        if '.tmp' in name or name.endswith('.part'):
            try:
                entry.unlink()
                removed += 1
            except OSError:
                continue
    return removed


def _load_download_archive() -> set:
    """
    è¯»å– download archive å¹¶ç¼“å­˜ç»“æœï¼Œé¿å…æ¯æ¬¡éƒ½é‡æ–°åŠ è½½å¤§æ–‡ä»¶
    """
    path = DOWNLOAD_ARCHIVE
    if not path:
        return set()
    video_title = None  # ç”¨äºå¼‚å¸¸åˆ†æ”¯çš„å®‰å…¨å¼•ç”¨
    video_id = None
    try:
        current_mtime = os.path.getmtime(path)
    except (FileNotFoundError, OSError):
        return set()

    cached_mtime = _download_archive_cache.get("mtime")
    if cached_mtime == current_mtime:
        return _download_archive_cache.get("entries", set())

    entries = set()
    try:
        with open(path, "r", encoding="utf-8") as archive_file:
            for line in archive_file:
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                parts = line.split()
                if not parts:
                    continue
                video_id = parts[-1]
                entries.add(video_id)
    except Exception:
        # å‡ºç°å¼‚å¸¸æ—¶ä¸æ›´æ–°ç¼“å­˜ï¼Œé¿å…ä½¿ç”¨ä¸å®Œæ•´æ•°æ®
        return _download_archive_cache.get("entries", set())

    _download_archive_cache["mtime"] = current_mtime
    _download_archive_cache["entries"] = entries
    return entries


def is_video_in_download_archive(video_id: str) -> bool:
    """
    åˆ¤æ–­æŒ‡å®šè§†é¢‘ ID æ˜¯å¦å·²ç»è®°å½•åœ¨ download archive ä¸­
    """
    if not video_id:
        return False
    entries = _load_download_archive()
    return video_id in entries


def _resolve_js_runtime_path(raw_path: str) -> str:
    """å°†ç”¨æˆ·è¾“å…¥çš„è·¯å¾„å±•å¼€ä¸ºç»å¯¹è·¯å¾„"""
    return os.path.abspath(
        os.path.expanduser(
            os.path.expandvars(raw_path)
        )
    )


def _detect_js_runtime():
    """
    æ£€æµ‹å¯ç”¨çš„ JavaScript è¿è¡Œæ—¶ï¼ˆé»˜è®¤ä¸º Denoï¼‰
    - æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡ YT_DLP_JS_RUNTIME=runtime_name:/path/to/bin è¦†ç›–
    - é»˜è®¤å›é€€åˆ° ~/.deno/bin/deno(.exe)
    """
    runtime_override = os.environ.get("YT_DLP_JS_RUNTIME")
    if runtime_override:
        runtime_name, _, runtime_path = runtime_override.partition(':')
        runtime_name = (runtime_name or 'deno').strip()
        runtime_config = {runtime_name: {}}
        runtime_path = runtime_path.strip()
        if runtime_path:
            resolved = _resolve_js_runtime_path(runtime_path)
            if os.path.exists(resolved):
                runtime_config[runtime_name]['path'] = resolved
                logger.info(f"ä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šçš„ JavaScript è¿è¡Œæ—¶: {runtime_name} -> {resolved}")
            else:
                logger.warning(f"ç¯å¢ƒå˜é‡ YT_DLP_JS_RUNTIME æŒ‡å®šçš„è·¯å¾„ä¸å­˜åœ¨: {resolved}")
        else:
            logger.trace(f"ä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šçš„ JavaScript è¿è¡Œæ—¶: {runtime_name} (PATH æœç´¢)")
        return runtime_config

    home_dir = os.path.expanduser("~")
    deno_binary = os.path.join(
        home_dir,
        ".deno",
        "bin",
        "deno.exe" if os.name == "nt" else "deno"
    )
    if os.path.exists(deno_binary):
        logger.info(f"æ£€æµ‹åˆ° Deno è¿è¡Œæ—¶ï¼Œå°†ç”¨äºè§£æ YouTube n signature: {deno_binary}")
        return {'deno': {'path': deno_binary}}

    logger.warning("æœªæ£€æµ‹åˆ°å¯ç”¨çš„ JavaScript è¿è¡Œæ—¶ï¼ŒYouTube ä¸‹è½½å¯èƒ½å¤±è´¥ (ç¼ºå°‘ Deno/Node/Bun/QuickJS)")
    return None


JS_RUNTIME_CONFIG = _detect_js_runtime()


def apply_js_runtime(opts: dict) -> dict:
    """ä¸º yt-dlp é…ç½®æ³¨å…¥ç»Ÿä¸€çš„ JavaScript è¿è¡Œæ—¶è®¾ç½®"""
    if JS_RUNTIME_CONFIG:
        opts['js_runtimes'] = copy.deepcopy(JS_RUNTIME_CONFIG)
    return opts


class TimestampedYTDLLogger:
    """è‡ªå®šä¹‰yt-dlpæ—¥å¿—å¤„ç†å™¨ï¼Œæ¡¥æ¥åˆ°ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ"""

    def __init__(self):
        self._logger = get_logger('downloader.yt-dlp')

    def _clean_message(self, msg):
        if msg is None:
            return ""
        text = str(msg).strip()
        if not text:
            return ""
        text = text.replace('[0;31m', '').replace('[0m', '')
        text = re.sub(r'\x1b\[[0-9;]*m', '', text).strip()
        text = re.sub(r'^(ERROR|WARNING|INFO)\s*:\s*', '', text, flags=re.IGNORECASE)
        text = re.sub(r'^\[download\]\s+', '', text, flags=re.IGNORECASE)
        return text

    def _is_progress_message(self, text: str) -> bool:
        """
        yt-dlp ä¼šç”¨ [download] xxx% ... æ¯æ¬¡å›è°ƒéƒ½åˆ·ä¸€æ¡ï¼Œè¿™é‡Œç›´æ¥ä¸¢å¼ƒï¼Œé¿å…æ—¥å¿—è¢«è¿›åº¦åˆ·å±ã€‚
        """
        return bool(re.match(r'^\\[download\\]\\s+\\d+(?:\\.\\d+)?%\\b', text))

    def _log_trace(self, msg):
        # æå‡é»˜è®¤æ—¥å¿—çº§åˆ«åˆ° INFOï¼šå¿½ç•¥ yt-dlp çš„ debug/trace è¾“å‡º
        return

    def debug(self, msg):
        self._log_trace(msg)

    def info(self, msg):
        cleaned = self._clean_message(msg)
        if cleaned:
            self._logger.info(cleaned)

    def warning(self, msg):
        cleaned = self._clean_message(msg)
        if cleaned:
            self._logger.warning(f'âš ï¸ yt-dlp: {cleaned}')

    def error(self, msg):
        cleaned = self._clean_message(msg)
        if not cleaned:
            return
        lower = cleaned.lower()
        if 'members-only content' in lower or 'join this channel' in lower:
            # yt-dlp æç¤ºä¼šå‘˜ä¸“å±å†…å®¹ï¼Œé™çº§ä¸º trace ä»¥å…åˆ·å±
            self._logger.trace(cleaned)
        else:
            self._logger.error(f'âŒ yt-dlp: {cleaned}')

    def critical(self, msg):
        cleaned = self._clean_message(msg)
        if cleaned:
            self._logger.critical(cleaned)

yt_base_url = "https://www.youtube.com/"

# æ–‡ä»¶ç³»ç»Ÿéæ³•å­—ç¬¦ï¼ˆWindows + Linuxï¼‰
ILLEGAL_FILENAME_CHARS = '<>:"/\\|?*'


def sanitize_filename(filename: str) -> str:
    """
    æ™ºèƒ½æ¸…ç†æ–‡ä»¶åï¼š
    - ä¿ç•™æ‰€æœ‰å¯è§å­—ç¬¦ï¼ˆä¸­æ–‡ã€è‹±æ–‡ã€æ ‡ç‚¹ã€è¡¨æƒ…ã€ç‰¹æ®Šç¬¦å·ç­‰ï¼‰
    - åªæ›¿æ¢æ–‡ä»¶ç³»ç»Ÿéæ³•å­—ç¬¦å’Œä¸å¯è§å­—ç¬¦
    
    Args:
        filename: åŸå§‹æ–‡ä»¶å
    
    Returns:
        æ¸…ç†åçš„å®‰å…¨æ–‡ä»¶å
    """
    result = []
    for char in filename:
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶ç³»ç»Ÿéæ³•å­—ç¬¦
        if char in ILLEGAL_FILENAME_CHARS:
            result.append('_')
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¯æ‰“å°å­—ç¬¦ï¼ˆæ’é™¤æ§åˆ¶å­—ç¬¦ã€é›¶å®½å­—ç¬¦ç­‰ä¸å¯è§å­—ç¬¦ï¼‰
        elif char.isprintable():
            result.append(char)
        # ä¸å¯è§å­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
        else:
            result.append('_')
    
    return ''.join(result)


def safe_rename_file(src, dst, max_retries=5):
    """
    å®‰å…¨é‡å‘½åæ–‡ä»¶ï¼ˆä».tmpåˆ°æ­£å¼æ–‡ä»¶åï¼‰ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶å¤„ç†æ–‡ä»¶é”å®šé—®é¢˜
    """
    for attempt in range(max_retries):
        try:
            os.rename(src, dst)
            return True
        except (OSError, PermissionError) as e:
            if attempt < max_retries - 1:
                log_with_context(
                    logger, logging.WARNING,
                    "æ–‡ä»¶é‡å‘½åå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•",
                    src=src, dst=dst, attempt=attempt + 1, max_retries=max_retries, error=str(e)
                )
                time.sleep(0.5 * (attempt + 1))  # é€’å¢å»¶è¿Ÿ
                continue
            else:
                log_with_context(
                    logger, logging.ERROR,
                    "æ–‡ä»¶é‡å‘½åå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°",
                    src=src, dst=dst, max_retries=max_retries, error=str(e)
                )
                # å°è¯•å¼ºåˆ¶åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(src)
                    logger.warning(f"å·²åˆ é™¤æ— æ³•é‡å‘½åçš„ä¸´æ—¶æ–‡ä»¶: {src}")
                except OSError:
                    logger.error(f"æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {src}")
                return False
        except Exception as e:
            log_with_context(
                logger, logging.ERROR,
                "æ–‡ä»¶é‡å‘½åæ„å¤–é”™è¯¯",
                src=src, dst=dst, error=str(e), error_type=type(e).__name__
            )
            return False


def record_download_entry(video_id: str, channel_name: Optional[str]) -> None:
    """
    æŠŠæˆåŠŸä¸‹è½½çš„è§†é¢‘è®°å½•åˆ°é…ç½®æä¾›è€…ï¼ˆæœ¬åœ°/Notionï¼‰ï¼Œé¿å…é‡å¤ä¸‹è½½ã€‚
    """
    try:
        provider = get_config_provider()
        if provider is None:
            return

        has_check = getattr(provider, "has_download_record", None)
        if callable(has_check) and has_check(video_id):
            logger.trace(f"ä¸‹è½½å­˜æ¡£è®°å½•å·²å­˜åœ¨: {video_id}")
            return

        add_record = getattr(provider, "add_download_record", None)
        if callable(add_record):
            success = add_record(video_id, channel_name or "unknown")
            if success:
                log_with_context(
                    logger, TRACE_LEVEL,
                    "å·²è®°å½•ä¸‹è½½å­˜æ¡£",
                    video_id=video_id,
                    yt_channel=channel_name
                )
            else:
                log_with_context(
                    logger, logging.WARNING,
                    "è®°å½•ä¸‹è½½å­˜æ¡£å¤±è´¥",
                    video_id=video_id,
                    yt_channel=channel_name
                )
    except Exception as err:
        log_with_context(
            logger, logging.ERROR,
            "è®°å½•ä¸‹è½½å­˜æ¡£å¼‚å¸¸",
            video_id=video_id,
            yt_channel=channel_name,
            error=str(err)
        )


def ensure_cookies_available() -> bool:
    """
    ç¡®ä¿ cookies æ–‡ä»¶å¯ç”¨ï¼š
    - notion æ¨¡å¼ï¼šæ¯æ¬¡å¯åŠ¨éƒ½ä» Notion è¦†ç›–å†™å…¥
    - local æ¨¡å¼ï¼šè‹¥æœ¬åœ°å­˜åœ¨åˆ™ç›´æ¥ä½¿ç”¨ï¼Œå¦åˆ™å°è¯•ä» Notion æ‹‰å–
    """
    try:
        provider = get_config_provider()
    except Exception as err:
        logger.warning(f"è·å–é…ç½®æä¾›è€…å¤±è´¥: {err}")
        provider = None

    is_notion_mode = provider and provider.__class__.__name__ == "NotionConfigProvider"

    if os.path.exists(COOKIES_FILE) and not is_notion_mode:
        return True

    if not provider:
        return os.path.exists(COOKIES_FILE)

    fetcher = getattr(provider, "get_cookies_content", None)
    if not callable(fetcher):
        return os.path.exists(COOKIES_FILE)

    try:
        content = fetcher()
    except Exception as err:
        logger.error(f"ä» Notion è·å– cookies å¤±è´¥: {err}")
        return os.path.exists(COOKIES_FILE)

    if not content or not content.strip():
        logger.warning("ä» Notion æœªè·å–åˆ°æœ‰æ•ˆ cookies æ•°æ®")
        return os.path.exists(COOKIES_FILE)

    target_dir = os.path.dirname(COOKIES_FILE)
    if target_dir and not os.path.exists(target_dir):
        os.makedirs(target_dir, exist_ok=True)

    try:
        with open(COOKIES_FILE, "w", encoding="utf-8") as f:
            f.write(content)
        logger.info(f"å·²ä» Notion åŒæ­¥ cookies è‡³æœ¬åœ°: {COOKIES_FILE}")
        return True
    except Exception as err:
        logger.error(f"å†™å…¥ cookies æ–‡ä»¶å¤±è´¥: {err}")
        return os.path.exists(COOKIES_FILE)


def member_content_filter(info_dict):
    """
    è¿‡æ»¤ä¼šå‘˜ä¸“å±å†…å®¹
    
    ç­–ç•¥ï¼š
    1. å‡ ä¹ä¸é¢„åˆ¤ï¼Œè®© yt-dlp + cookies å†³å®šèƒ½å¦ä¸‹è½½
    2. åŸå› ï¼š
       - ç”¨æˆ·å¯èƒ½è´­ä¹°äº†æŸäº›é¢‘é“çš„ä¼šå‘˜
       - æœ‰äº›ä¸»æ’­ä¼šä¸‹æ”¾ä¼šå‘˜è§†é¢‘
       - cookies ä¸­åŒ…å«ä¼šå‘˜æƒé™ä¿¡æ¯
    3. åªè¿‡æ»¤æ˜ç¡®çš„ç§äººè§†é¢‘ï¼ˆè¿™ä¸ªç¡®å®ä¸‹è½½ä¸äº†ï¼‰
    4. ä¸‹è½½å¤±è´¥æ—¶ï¼Œå†ä»é”™è¯¯ä¿¡æ¯åˆ¤æ–­æ˜¯å¦ä¸ºä¼šå‘˜å†…å®¹
    """
    try:
        video_id = info_dict.get("id", "")

        # åªè¿‡æ»¤ç§äººè§†é¢‘ï¼ˆè¿™ä¸ªç¡®å®æ— æ³•ä¸‹è½½ï¼‰
        if info_dict.get("availability") == "private":
            logger.trace(f"â­ï¸ è·³è¿‡ç§äººè§†é¢‘: {video_id}")
            return "ç§äººè§†é¢‘"

        # å…¶ä»–æƒ…å†µï¼šå…è®¸å°è¯•ä¸‹è½½
        # åŒ…æ‹¬ subscriber_onlyï¼Œå› ä¸ºç”¨æˆ·çš„ cookies å¯èƒ½æœ‰ä¼šå‘˜æƒé™
        return None
        
    except Exception as e:
        logger.warning(f"ä¼šå‘˜è¿‡æ»¤å™¨é”™è¯¯: {e}")
        return None


def combined_filter(info_dict):
    """ç»„åˆè¿‡æ»¤å™¨ï¼šåŒæ—¶åº”ç”¨æ—¶é—´è¿‡æ»¤å’Œä¼šå‘˜å†…å®¹è¿‡æ»¤"""
    try:
        # å…ˆæ£€æŸ¥ä¼šå‘˜å†…å®¹è¿‡æ»¤
        member_result = member_content_filter(info_dict)
        if member_result:
            return member_result

        # å†æ£€æŸ¥æ—¶é—´è¿‡æ»¤
        time_result = oneday_filter(info_dict)
        if time_result:
            return time_result

        return None
    except Exception as e:
        logger.warning(f"ç»„åˆè¿‡æ»¤å™¨é”™è¯¯: {e}")
        return None


def oneday_filter(info_dict):
    """è¿‡æ»¤æœ€è¿‘Nå¤©çš„è§†é¢‘ï¼ˆNä»é…ç½®è¯»å–ï¼‰"""
    try:
        timestamp = info_dict.get("timestamp")
        upload_datetime = None
        
        # ä¼˜å…ˆä½¿ç”¨ timestamp
        if timestamp:
            upload_datetime = datetime.datetime.fromtimestamp(
                timestamp, tz=datetime.timezone.utc
            )
        # å›é€€åˆ° upload_date
        elif info_dict.get("upload_date"):
            upload_date = info_dict.get("upload_date")
            naive_upload_datetime = datetime.datetime.strptime(upload_date, "%Y%m%d")
            upload_datetime = naive_upload_datetime.replace(tzinfo=datetime.timezone.utc)
        else:
            # æ— æ—¶é—´ä¿¡æ¯ï¼Œä¸è¿‡æ»¤
            return None
            
        # ä»é…ç½®è¯»å–è¿‡æ»¤å¤©æ•°ï¼ˆæ”¯æŒçƒ­é‡è½½ï¼‰
        filter_days = get_filter_days()
        days_ago = datetime.datetime.now(datetime.timezone.utc) - datetime.timedelta(days=filter_days)
        
        if upload_datetime > days_ago:
            # é€šè¿‡è¿‡æ»¤ï¼ˆæœ€è¿‘Nå¤©çš„è§†é¢‘ï¼‰
            return None
        else:
            # æ‹’ç»ï¼ˆè¶…è¿‡Nå¤©ï¼‰
            return f"è§†é¢‘è¶…è¿‡{filter_days}å¤©"
            
    except Exception as e:
        logger.warning(f"è¿‡æ»¤å™¨é”™è¯¯: {str(e)}")
        return None


def check_cookies():
    """æ£€æŸ¥cookiesæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ"""
    if not os.path.exists(COOKIES_FILE):
        if ensure_cookies_available() and os.path.exists(COOKIES_FILE):
            return True
        logger.error("æœªæ‰¾åˆ°cookiesæ–‡ä»¶ï¼")
        logger.info("è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")
        logger.info("1. å®‰è£…Chromeæ‰©å±•ï¼š'Cookie-Editor'")
        logger.info("2. è®¿é—® YouTube å¹¶ç¡®ä¿å·²ç™»å½•")
        logger.info("3. ç‚¹å‡»Cookie-Editoræ‰©å±•å›¾æ ‡")
        logger.info("4. ç‚¹å‡»'Export'æŒ‰é’®ï¼Œé€‰æ‹©'Netscape HTTP Cookie File'æ ¼å¼")
        logger.info("5. å°†å¯¼å‡ºçš„å†…å®¹ä¿å­˜åˆ°é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ 'youtube.cookies' æ–‡ä»¶ä¸­")
        logger.info("6. å®Œæˆåé‡æ–°è¿è¡Œç¨‹åº")
        return False
    return True


def get_ydl_opts(custom_opts=None):
    # ç¡®ä¿éŸ³é¢‘æ–‡ä»¶å¤¹å­˜åœ¨
    if not os.path.exists(AUDIO_FOLDER):
        os.makedirs(AUDIO_FOLDER)
        logger.info(f"å·²åˆ›å»ºéŸ³é¢‘ç›®å½•: {AUDIO_FOLDER}")
    cleanup_incomplete_downloads(AUDIO_FOLDER)

    # ä½¿ç”¨ .tmp åç¼€æ¥æ ‡è®°æ­£åœ¨ä¸‹è½½çš„æ–‡ä»¶
    # æ³¨æ„ï¼šFFmpegåå¤„ç†å™¨ä¼šæ›¿æ¢æ–‡ä»¶æ‰©å±•åï¼Œæ‰€ä»¥æˆ‘ä»¬åªç”¨ä¸€ä¸ªæ¨¡æ¿
    # æœ€ç»ˆæ ¼å¼ï¼šfilename.tmp.m4a (yt-dlpä¸‹è½½ä¸ºfilename.tmpï¼ŒFFmpegè½¬æ¢ä¸ºfilename.tmp.m4a)
    # æ–‡ä»¶åæ ¼å¼ï¼š{video_id}.{title}.m4aï¼ˆä½¿ç”¨ id è€Œä¸æ˜¯ uploaderï¼Œä¾¿äºè®°å½•å’Œè¿½è¸ªï¼‰
    base_format = "bestvideo[height<=480][vcodec!=none]+bestaudio/best"
    base_opts = {
        "format": base_format,
        "outtmpl": os.path.join(AUDIO_FOLDER, "%(id)s.%(title)s.tmp"),
        "logger": TimestampedYTDLLogger(),  # ä½¿ç”¨è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼
        "postprocessors": [
            {
                "key": "FFmpegExtractAudio",
                "preferredcodec": "m4a",  # ä½¿ç”¨ MP4/M4A å®¹å™¨ï¼Œç¡®ä¿æ—¶é•¿å…ƒæ•°æ®å‡†ç¡®
                "preferredquality": "64",
                "nopostoverwrites": False,
            }
        ],
        "keepvideo": False,  # ä¸ä¿ç•™åŸå§‹è§†é¢‘æ–‡ä»¶
        "cookiefile": COOKIES_FILE,
        "sleep_interval": 88,
        "max_sleep_interval": 208,
        "random_sleep": True,
        "ignoreerrors": True,  # è·³è¿‡é”™è¯¯è§†é¢‘ï¼ˆå¦‚ä¼šå‘˜å†…å®¹ï¼‰ï¼Œç»§ç»­å¤„ç†å…¶ä»–è§†é¢‘
        "format_sort": ["+hasaud", "+hasvid", "+codec:opus", "+codec:aac", "+codec:mp3"],
        "format_fallback": True,
        "progress_hooks": [progress_hook],
        "http_headers": {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "en-us,en;q=0.5",
            "Sec-Fetch-Mode": "navigate",
        }
    }
    
    base_opts = apply_js_runtime(base_opts)
    
    if custom_opts:
        base_opts.update(custom_opts)
    
    return base_opts


def progress_hook(d):
    if d['status'] == 'finished':
        filename = os.path.basename(d.get('filename', ''))
        # è·³è¿‡ yt-dlp ä¸‹è½½ä¸­é—´äº§ç”Ÿçš„ .tmp.fXXX ç‰‡æ®µæ—¥å¿—ï¼Œé¿å…é‡å¤å™ªéŸ³
        if ".tmp.f" in filename:
            return
        logger.trace(f"ä¸‹è½½å®Œæˆ: {filename}")
    elif d['status'] == 'already_downloaded':
        logger.trace(f"å·²å­˜åœ¨: {d.get('title', '')}")


def get_available_format(url):
    """è·å–è§†é¢‘çš„å¯ç”¨æ ¼å¼ï¼Œå¹¶é€‰æ‹©ä¸€ä¸ªåˆé€‚çš„æ ¼å¼è¿›è¡Œä¸‹è½½"""
    ydl_opts = {
        "listformats": True,
        "cookiefile": COOKIES_FILE,
        "quiet": True,
    }
    ydl_opts = apply_js_runtime(ydl_opts)
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(url, download=False)
        formats = info.get("formats", [])
        audio_formats = [f for f in formats if f.get("acodec") != "none"]
        if audio_formats:
            return audio_formats[0].get("format_id", "bestaudio/best")
        video_formats = [f for f in formats if f.get("vcodec") != "none"]
        if video_formats:
            return video_formats[0].get("format_id", "best")
        if formats:
            return formats[0].get("format_id", "best")
        return "best"


def dl_audio_latest(channel_name, audio_folder=None, group_name=None):
    """
    ä¸‹è½½æŒ‡å®šYouTubeé¢‘é“çš„æœ€æ–°éŸ³é¢‘
    
    Args:
        channel_name: YouTubeé¢‘é“åç§°
        audio_folder: éŸ³é¢‘ä¿å­˜ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨AUDIO_FOLDERï¼‰
        group_name: é¢‘é“ç»„åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
    """
    if not check_cookies():
        return False
    
    # ä½¿ç”¨æŒ‡å®šçš„ç›®å½•ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤ç›®å½•
    target_folder = audio_folder if audio_folder else AUDIO_FOLDER
    
    if not os.path.exists(target_folder):
        os.makedirs(target_folder)
        logger.info(f"å·²åˆ›å»ºéŸ³é¢‘ç›®å½•: {target_folder}")

    # ä»é…ç½®è¯»å–æœ€å¤§è§†é¢‘æ•°ï¼ˆæ”¯æŒçƒ­é‡è½½ï¼‰
    max_videos = get_max_videos_per_channel()
    
    custom_opts = {
        "download_archive": DOWNLOAD_ARCHIVE,
        "playlistend": max_videos,
        "match_filter": combined_filter,
        "keepvideo": False,
        "outtmpl": os.path.join(target_folder, "%(uploader)s.%(id)s.%(title)s.%(ext)s"),  # æ–‡ä»¶åæ ¼å¼ï¼š{é¢‘é“å}.{video_id}.{title}.m4a
    }
    
    ydl_opts = get_ydl_opts(custom_opts)
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total': 0,
        'success': 0,
        'already_exists': 0,
        'filtered': 0,
        'archived': 0,
        'member_only': 0,
        'error': 0,
        'details': []
    }
    # å…œåº•åˆå§‹åŒ–ï¼Œé˜²æ­¢åœ¨æ‹‰å–åˆ—è¡¨é˜¶æ®µå¼‚å¸¸æ—¶æœªèµ‹å€¼å°±è¢«å¼•ç”¨
    video_title = None
    video_id = None
    
    # ç¬¬ä¸€æ­¥ï¼šè·å–è§†é¢‘åˆ—è¡¨ï¼ˆä½¿ç”¨æµ‹è¯•è„šæœ¬ä¸­æˆåŠŸçš„é…ç½®ï¼‰
    list_opts = {
        "quiet": True,
        "playlistend": max_videos,
        "cookiefile": COOKIES_FILE,
    }
    list_opts = apply_js_runtime(list_opts)
    
    with yt_dlp.YoutubeDL(list_opts) as list_ydl:
        try:
            # YouTubeé¢‘é“ç»“æ„å˜åŒ–ï¼šç›´æ¥è®¿é—® /videos é¡µé¢è·å–è§†é¢‘åˆ—è¡¨
            url = f"{yt_base_url}{channel_name}/videos"
            channel_info = list_ydl.extract_info(url, download=False)
            
            
            if not channel_info or 'entries' not in channel_info:
                log_with_context(
                    logger, logging.WARNING,
                    "é¢‘é“æœªæ‰¾åˆ°è§†é¢‘æˆ–ä¿¡æ¯ä¸å®Œæ•´",
                    yt_channel=channel_name
                )
                return False

            # å¤„ç†è¿”å›çš„è§†é¢‘åˆ—è¡¨
            # æ³¨æ„ï¼šä¸ä½¿ç”¨ extract_flat æ—¶ï¼Œentries å¯èƒ½æ˜¯ LazyList æˆ– generator
            entries_to_download = []
            raw_entries = channel_info.get('entries') if channel_info else []
            
            if raw_entries:
                # éå† entriesï¼ˆå¯èƒ½æ˜¯ generatorï¼‰ä»¥ç­›é€‰æœ‰æ•ˆæ¡ç›®
                for entry in raw_entries:
                    if entry and isinstance(entry, dict):
                        entries_to_download.append(entry)
                        # åªè·å– max_videos ä¸ª
                        if len(entries_to_download) >= max_videos:
                            break
            
            # è®°å½•æ‰¾åˆ°çš„è§†é¢‘æ€»æ•°
            stats['total'] = len(entries_to_download)
            log_with_context(
                logger, logging.INFO,
                "ğŸ“‹ é¢‘é“è§†é¢‘åˆ—è¡¨è·å–å®Œæˆ",
                yt_channel=channel_name,
                total_videos=stats['total'],
                max_to_process=max_videos,
                tg_channel=group_name if group_name else None
            )

            for idx, video_info in enumerate(entries_to_download, 1):
                video_title = video_info.get('title', 'æœªçŸ¥æ ‡é¢˜')
                video_id = video_info.get('id', 'unknown')
                
                # ä½¿ç”¨ extract_flat åï¼Œwebpage_url å¯èƒ½ç¼ºå¤±ï¼Œéœ€è¦ä» id æ„å»º
                video_url = video_info.get("webpage_url")
                if not video_url and video_id and video_id != 'unknown':
                    # ä» video_id æ„å»ºå®Œæ•´çš„ YouTube URL
                    video_url = f"https://www.youtube.com/watch?v={video_id}"
                    logger.trace(f"ä» video_id æ„å»º URL: {video_url}")
                
                if not video_url:
                    logger.trace(f"è·³è¿‡æ¡ç›®ï¼Œæ— URLä¸”æ— ID: {video_title}")
                    stats['error'] += 1
                    stats['details'].append({
                        'index': idx,
                        'title': video_title,
                        'id': video_id,
                        'status': 'no_url',
                        'reason': 'æ— è§†é¢‘URL'
                    })
                    continue

                # è·å–ä¸Šä¼ æ—¶é—´ï¼ˆç”¨äºæ—¥å¿—å’Œè¿‡æ»¤ï¼‰
                upload_date_str = "æœªçŸ¥"
                if video_info.get('timestamp'):
                    upload_dt = datetime.datetime.fromtimestamp(video_info.get('timestamp'), tz=datetime.timezone.utc)
                    upload_date_str = upload_dt.strftime('%m-%d')
                elif video_info.get('upload_date'):
                    upload_date_str = video_info.get('upload_date')[4:]  # å–æœˆæ—¥éƒ¨åˆ† MMDD
                    upload_date_str = f"{upload_date_str[:2]}-{upload_date_str[2:]}"
                
                # åº”ç”¨è¿‡æ»¤å™¨ï¼ˆæ—¥æœŸè¿‡æ»¤ã€ä¼šå‘˜å†…å®¹è¿‡æ»¤ç­‰ï¼‰ï¼›å‘½ä¸­è¿‡æ»¤æ—¶ç›´æ¥è®°å½•è·³è¿‡åŸå› ã€‚
                filter_result = combined_filter(video_info)
                if filter_result:
                    log_with_context(
                        logger, TRACE_LEVEL,
                        f"â­ï¸ è·³è¿‡è§†é¢‘ï¼ˆ{filter_result}ï¼‰",
                        yt_channel=channel_name,
                        title=video_title[:60] + "..." if len(video_title) > 60 else video_title,
                        video_id=video_id,
                        index=idx,
                        total=stats['total'],
                        upload_date=upload_date_str
                    )
                    stats['filtered'] += 1
                    stats['details'].append({
                        'index': idx,
                        'title': video_title,
                        'id': video_id,
                        'status': 'filtered',
                        'reason': filter_result
                    })
                    continue

                # æ„å»ºæ–‡ä»¶åï¼š{é¢‘é“å}.{video_id}.{title}.m4a
                uploader = video_info.get('uploader') or video_info.get('channel') or channel_name or 'UnknownChannel'
                safe_uploader = sanitize_filename(uploader)
                
                fulltitle = video_info.get('fulltitle') or video_info.get('title') or 'UnknownTitle'
                safe_title = sanitize_filename(fulltitle)
                
                expected_audio_ext = ".m4a"
                final_audio_filename_stem = f"{safe_uploader}.{video_id}.{safe_title}"
                
                temp_audio_path_without_ext = os.path.join(target_folder, final_audio_filename_stem)
                expected_temp_audio_path = temp_audio_path_without_ext + ".tmp" + expected_audio_ext
                possible_temp_paths = [
                    expected_temp_audio_path,
                    temp_audio_path_without_ext + expected_audio_ext,
                ]

                # æ­£å¼æ–‡ä»¶è·¯å¾„ï¼ˆä¸å¸¦ .tmpï¼‰
                final_destination_audio_path = os.path.join(target_folder, f"{final_audio_filename_stem}{expected_audio_ext}")

                if os.path.exists(final_destination_audio_path):
                    log_with_context(
                        logger, TRACE_LEVEL,
                        f"â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ {video_id}",
                        yt_channel=channel_name
                    )
                    stats['already_exists'] += 1
                    stats['details'].append({
                        'index': idx,
                        'title': video_title,
                        'id': video_id,
                        'status': 'already_exists',
                        'reason': 'æ–‡ä»¶å·²å­˜åœ¨'
                    })
                    continue

                if is_video_in_download_archive(video_id):
                    stats['archived'] += 1
                    stats['details'].append({
                        'index': idx,
                        'title': video_title,
                        'id': video_id,
                        'status': 'archived',
                        'reason': 'archive_hit_no_file'
                    })
                    continue
                
                current_video_ydl_opts = ydl_opts.copy()
                # FFmpegåå¤„ç†å™¨ä¼šå°† filename.tmp è½¬æ¢ä¸º filename.tmp.m4a
                current_video_ydl_opts['outtmpl'] = temp_audio_path_without_ext + '.tmp'

                # å…ˆæ£€æŸ¥è¿‡æ»¤å™¨ï¼ˆé¿å…è¢«è¿‡æ»¤çš„è§†é¢‘è¢«è¯¯æŠ¥ä¸ºä¸‹è½½å¤±è´¥ï¼‰
                filter_result = combined_filter(video_info)
                if filter_result:
                    log_with_context(
                        logger, TRACE_LEVEL,
                        f"â­ï¸ è·³è¿‡ {video_id} ({filter_result})",
                        yt_channel=channel_name
                    )
                    stats['filtered'] += 1
                    stats['details'].append({
                        'index': idx,
                        'title': video_title,
                        'id': video_id,
                        'status': 'filtered',
                        'reason': filter_result
                    })
                    continue

                try:
                    with yt_dlp.YoutubeDL(current_video_ydl_opts) as video_ydl:
                        video_ydl.download([video_url]) 
                    
                    temp_audio_path = next((p for p in possible_temp_paths if os.path.exists(p)), None)
                    if temp_audio_path:
                        logger.trace(f"è½¬æ¢å®Œæˆ: {os.path.basename(temp_audio_path)}")
                        if os.path.normcase(temp_audio_path) == os.path.normcase(final_destination_audio_path):
                            rename_ok = True
                        else:
                            rename_ok = safe_rename_file(temp_audio_path, final_destination_audio_path)

                        if rename_ok:
                            file_size_mb = os.path.getsize(final_destination_audio_path) / (1024 * 1024)
                            log_with_context(
                                logger, logging.INFO,
                                f"âœ… ä¸‹è½½æˆåŠŸ {video_id}",
                                yt_channel=channel_name,
                                size_mb=round(file_size_mb, 2)
                            )
                            stats['success'] += 1
                            stats['details'].append({
                                'index': idx,
                                'title': video_title,
                                'id': video_id,
                                'status': 'success',
                                'reason': 'ä¸‹è½½æˆåŠŸ',
                                'size_mb': round(file_size_mb, 2)
                            })

                            record_download_entry(video_id, channel_name)

                            # è§†é¢‘é—´å»¶è¿Ÿï¼ˆå¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªè§†é¢‘ï¼‰
                            if idx < stats['total']:
                                video_delay_min = get_video_delay_min()
                                video_delay_max = get_video_delay_max()
                                if video_delay_max > 0:  # åªåœ¨é…ç½®äº†å»¶è¿Ÿæ—¶æ‰æ‰§è¡Œ
                                    delay = random.uniform(video_delay_min, video_delay_max)
                                    log_with_context(
                                        logger, logging.INFO,
                                        "â³ è§†é¢‘é—´å»¶è¿Ÿ",
                                        yt_channel=channel_name,
                                        delay_seconds=round(delay, 2),
                                        current_video=idx,
                                        total_videos=stats['total']
                                    )
                                    time.sleep(delay)
                        else:
                            log_with_context(
                                logger, logging.ERROR,
                                f"âŒ é‡å‘½åå¤±è´¥ {video_id}",
                                yt_channel=channel_name
                            )
                            stats['error'] += 1
                            stats['details'].append({
                                'index': idx,
                                'title': video_title,
                                'id': video_id,
                                'status': 'error',
                                'reason': 'æ–‡ä»¶é‡å‘½åå¤±è´¥'
                            })
                    else:
                        log_with_context(
                            logger, logging.ERROR,
                            f"âŒ è½¬æ¢å¤±è´¥ {video_id} (æ–‡ä»¶æœªæ‰¾åˆ°)",
                            yt_channel=channel_name
                        )
                        original_downloaded_file_actual_ext = None
                        for ext_try in ['.webm', '.mp4', '.mkv', '.flv', '.avi', '.mov', '.opus', '.ogg', '.mp3']:
                            potential_orig_file = temp_audio_path_without_ext + ext_try + '.tmp'
                            if os.path.exists(potential_orig_file):
                                original_downloaded_file_actual_ext = ext_try
                                logger.warning(f"æ‰¾åˆ°åŸå§‹ä¸‹è½½æ–‡ä»¶: {potential_orig_file}ï¼Œä½†æœªè½¬æ¢ä¸º {expected_audio_ext}")
                                break
                        if not original_downloaded_file_actual_ext:
                            logger.error(f"ğŸ§© åŸå§‹ä¸‹è½½æ–‡ä»¶ä¹Ÿæœªæ‰¾åˆ° (å°è¯•çš„æ¨¡æ¿: {temp_audio_path_without_ext}.*.tmp)")

                        stats['error'] += 1
                        stats['details'].append({
                            'index': idx,
                            'title': video_title,
                            'id': video_id,
                            'status': 'error',
                            'reason': 'è½¬æ¢å¤±è´¥æˆ–æ–‡ä»¶æœªæ‰¾åˆ°'
                        })

                except yt_dlp.utils.DownloadError as de:
                    error_str = str(de)
                    error_lower = error_str.lower()
                    if "already been recorded in the archive" in error_str:
                        log_with_context(
                            logger, logging.INFO,
                            "è§†é¢‘å·²åœ¨å­˜æ¡£ä¸­è®°å½•ï¼Œè·³è¿‡",
                            yt_channel=channel_name,
                            video_index=f"{idx}/{stats['total']}",
                            title=video_title,
                            video_id=video_id
                        )
                        stats['archived'] += 1
                        stats['details'].append({
                            'index': idx,
                            'title': video_title,
                            'id': video_id,
                            'status': 'archived',
                            'reason': 'å·²åœ¨å­˜æ¡£ä¸­'
                        })
                    elif "members-only" in error_lower or "member" in error_lower or "premium" in error_lower or "subscriber" in error_lower:
                        log_with_context(
                            logger, logging.INFO,
                            f"ğŸ”’ ä¼šå‘˜ä¸“å± {video_id} (ä¸‹è½½è¢«æ‹’ç»)",
                            yt_channel=channel_name
                        )
                        stats['member_only'] += 1
                        stats['details'].append({
                            'index': idx,
                            'title': video_title,
                            'id': video_id,
                            'status': 'member_only',
                            'reason': 'ä¼šå‘˜ä¸“å±å†…å®¹ï¼ˆä¸‹è½½æ—¶ç¡®è®¤ï¼‰'
                        })
                    elif "premieres in" in error_lower or "premiere" in error_lower:
                        # YouTube Premiereï¼ˆé¦–æ˜ ï¼‰è§†é¢‘ï¼Œå°šæœªåˆ°é¦–æ˜ æ—¶é—´
                        premiere_info = error_str.split(":")[-1].strip() if ":" in error_str else "å¾…é¦–æ˜ "
                        log_with_context(
                            logger, logging.INFO,
                            f"â° å¾…é¦–æ˜  {video_id}",
                            yt_channel=channel_name,
                            premiere_info=premiere_info
                        )
                        stats['filtered'] += 1
                        stats['details'].append({
                            'index': idx,
                            'title': video_title,
                            'id': video_id,
                            'status': 'premiere',
                            'reason': f'å¾…é¦–æ˜ : {premiere_info}'
                        })
                    elif 'requested range not satisfiable' in error_lower or 'http error 416' in error_lower:
                        removed_chunks = cleanup_partial_files_for_base(temp_audio_path_without_ext)
                        log_with_context(
                            logger, logging.WARNING,
                            f'ğŸ§¹ HTTP 416ï¼šæ£€æµ‹åˆ°æ— æ•ˆçš„ä¸‹è½½èŒƒå›´ï¼Œå·²æ¸…ç†æ®‹ç•™ç‰‡æ®µ {video_id}',
                            yt_channel=channel_name,
                            video_id=video_id,
                            removed_chunks=removed_chunks
                        )
                        stats['error'] += 1
                        stats['details'].append({
                            'index': idx,
                            'title': video_title,
                            'id': video_id,
                            'status': 'error',
                            'reason': 'HTTP 416 - range æ— æ•ˆ'
                        })
                    
                    else:
                        # ç®€çŸ­çš„é”™è¯¯ä¿¡æ¯
                        error_msg = str(de)[:100] if len(str(de)) > 100 else str(de)
                        log_with_context(
                            logger, logging.ERROR,
                            f"âŒ ä¸‹è½½å¤±è´¥ {video_id}",
                            yt_channel=channel_name,
                            error=error_msg
                        )
                        stats['error'] += 1
                        stats['details'].append({
                            'index': idx,
                            'title': video_title,
                            'id': video_id,
                            'status': 'error',
                            'reason': f'yt-dlpé”™è¯¯: {str(de)[:100]}'
                        })
                    if os.path.exists(expected_temp_audio_path):
                        try: 
                            os.remove(expected_temp_audio_path)
                            logger.trace(f"å·²æ¸…ç†éƒ¨åˆ†ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶: {expected_temp_audio_path}")
                        except OSError: pass
                    for ext_try in ['.webm', '.mp4', '.mkv']:
                        potential_orig_file = temp_audio_path_without_ext + ext_try + '.tmp'
                        if os.path.exists(potential_orig_file):
                            try:
                                os.remove(potential_orig_file)
                                logger.trace(f"å·²æ¸…ç†éƒ¨åˆ†ä¸‹è½½çš„è§†é¢‘æ–‡ä»¶: {potential_orig_file}")
                            except OSError: pass
                            break
                    continue
                except Exception as e:
                    error_msg = str(e)[:100] if len(str(e)) > 100 else str(e)
                    log_with_context(
                        logger, logging.ERROR,
                        f"âŒ æœªçŸ¥é”™è¯¯ {video_id}",
                        yt_channel=channel_name,
                        error_type=type(e).__name__,
                        error=error_msg
                    )
                    stats['error'] += 1
                    stats['details'].append({
                        'index': idx,
                        'title': video_title,
                        'id': video_id,
                        'status': 'error',
                        'reason': f'{type(e).__name__}: {str(e)[:100]}'
                    })
                    continue
            
            # è¾“å‡ºé¢‘é“å¤„ç†æ±‡æ€»
            log_with_context(
                logger, logging.INFO,
                f"âœ… é¢‘é“å¤„ç†å®Œæˆ",
                yt_channel=channel_name,
                total_videos=stats['total'],
                success=stats['success'],
                filtered=stats['filtered'],
                already_exists=stats['already_exists'],
                archived=stats['archived'],
                member_only=stats['member_only'],
                error=stats['error']
            )
            
            # è¯¦ç»†åˆ—è¡¨ä¿¡æ¯å·²é€šè¿‡æ¯ä¸ªè§†é¢‘çš„ç‹¬ç«‹æ—¥å¿—è¾“å‡ºï¼Œæ­¤å¤„ä¸å†é‡å¤è¾“å‡º
            # æ ¼å¼åŒ–çš„æ–‡æœ¬åˆ—è¡¨ä¸é€‚åˆ JSON ç»“æ„åŒ–æ—¥å¿—
        
        except Exception as e:
            error_str = str(e)
            error_type = type(e).__name__
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç›´æ’­é¢„å‘Šï¼ˆè¿˜æœªå¼€å§‹çš„ç›´æ’­ï¼‰
            if "live event will begin in" in error_str.lower():
                logger.info(f"é¢‘é“ {channel_name} åŒ…å«ç›´æ’­é¢„å‘Šè§†é¢‘ï¼Œç¨åè‡ªåŠ¨ä¸‹è½½")
                return True  # ä¸ç®—é”™è¯¯ï¼Œè¿”å›æˆåŠŸ
            
            # æ£€æŸ¥æ˜¯å¦ä¸º YouTube Premiereï¼ˆé¦–æ˜ ï¼‰è§†é¢‘
            if "premieres in" in error_str.lower() or "premiere" in error_str.lower():
                logger.info(f"é¢‘é“ {channel_name} åŒ…å«å¾…é¦–æ˜ è§†é¢‘ï¼Œç¨åè‡ªåŠ¨ä¸‹è½½")
                return True  # ä¸ç®—é”™è¯¯ï¼Œè¿”å›æˆåŠŸ
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºä¼šå‘˜ä¸“å±å†…å®¹é”™è¯¯ï¼ˆé¢‘é“è§†é¢‘éƒ½æ˜¯ä¼šå‘˜å†…å®¹æ—¶ä¼šåœ¨è·å–åˆ—è¡¨é˜¶æ®µå°±æŠ¥é”™ï¼‰
            if ("members-only" in error_str.lower() or 
                ("member" in error_str.lower() and "join this channel" in error_str.lower())):
                safe_title = video_title or "æœªçŸ¥æ ‡é¢˜"
                safe_id = video_id or "unknown"
                log_with_context(
                    logger, TRACE_LEVEL,
                    f"â­ï¸ é¢‘é“å½“å‰è§†é¢‘ã€Š{safe_title}ã€‹ä¸ºä¼šå‘˜ä¸“å±ï¼Œè·³è¿‡",
                    yt_channel=channel_name,
                    video_title=safe_title,
                    video_id=safe_id
                )
                return True  # ä¸ç®—é”™è¯¯ï¼Œåªæ˜¯æš‚æ—¶æ²¡æœ‰å¯ä¸‹è½½å†…å®¹
            
            # è®°å½•å®é™…é”™è¯¯ï¼ˆä¸åŒ…å« tracebackï¼Œé¿å…æ—¥å¿—è¿‡é•¿ï¼‰
            # åªä¿ç•™é”™è¯¯æ¶ˆæ¯çš„å‰200ä¸ªå­—ç¬¦
            error_msg = error_str[:200] if len(error_str) > 200 else error_str
            log_with_context(
                logger, logging.ERROR,
                f"âŒ å¤„ç†é¢‘é“å¤±è´¥",
                yt_channel=channel_name,
                error_type=error_type,
                error=error_msg
            )
            
            if "HTTP Error 404" in error_str:
                logger.error(f"é¢‘é“ {channel_name} ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®ï¼Œè¯·æ£€æŸ¥é¢‘é“åç§°æ˜¯å¦æ­£ç¡®ã€‚")
            elif any(msg in error_str.lower() for msg in ["sign in to confirm", "unable to download api page", "not a bot", "consent"]):
                logger.error("Cookieså¯èƒ½å·²è¿‡æœŸæˆ–éœ€è¦åŒæ„YouTubeæ”¿ç­–ï¼")
                logger.info("è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ›´æ–°cookiesï¼š")
                logger.info("1. (æµè§ˆå™¨) æ¸…é™¤youtube.comçš„cookiesï¼Œè®¿é—®YouTubeå¹¶ç¡®ä¿å·²ç™»å½•åŠå¤„ç†ä»»ä½•å¼¹çª—ã€‚")
                logger.info("2. (æµè§ˆå™¨) ä½¿ç”¨Cookie-Editorå¯¼å‡ºæ–°çš„cookiesã€‚")
                logger.info("3. å°†æ–°çš„cookieså†…å®¹è¦†ç›–ä¿å­˜åˆ° 'youtube.cookies' æ–‡ä»¶ã€‚")
                logger.info("4. å®ŒæˆåæŒ‰ Enter é”®ç»§ç»­ç¨‹åºæˆ–é‡å¯ç¨‹åºã€‚")
                return False
    return True


def closest_after_filter(target_timestamp):
    def filter_func(info_dict):
        timestamp = info_dict.get("timestamp")
        if not timestamp:
            return "No timestamp available"

        if timestamp <= target_timestamp:
            return "Video is older than the target time"

        return None

    return filter_func


def update_channel_info_file(channel_name, target_timestamp, info_file_path):
    updated = False
    lines = []

    if os.path.exists(STORY_FILE):
        with open(STORY_FILE, "r", encoding="utf-8") as f:
            lines = f.readlines()

    for i, line in enumerate(lines):
        if line.startswith(channel_name):
            lines[i] = f"{channel_name} {target_timestamp}\n"
            updated = True
            break

    if not updated:
        lines.append(f"{channel_name} {target_timestamp}\n")

    with open(STORY_FILE, "w", encoding="utf-8") as f:
        f.writelines(lines)


def dl_audio_closest_after(au_folder, channel_name, target_timestamp=None):
    log_with_context(
        logger, logging.INFO,
        "å¼€å§‹å¤„ç†é¢‘é“å†å²è§†é¢‘",
        yt_channel=channel_name
    )
    if not check_cookies():
        return False
    
    ydl_opts = get_ydl_opts()
    logger.trace("å·²é…ç½®ä¸‹è½½é€‰é¡¹ (å°†ä½¿ç”¨ä¸´æ—¶ç›®å½•)")
    
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        try:
            logger.info("æ­£åœ¨è·å–é¢‘é“ä¿¡æ¯...")
            info_dict = ydl.extract_info(f"{yt_base_url}{channel_name}", download=False)
            if not info_dict:
                logger.error(f"æ— æ³•è·å–é¢‘é“ä¿¡æ¯: {channel_name}")
                return False
                
            logger.info("æ­£åœ¨å¤„ç†è§†é¢‘åˆ—è¡¨ä»¥æŸ¥æ‰¾ç›®æ ‡è§†é¢‘...")
            entries = info_dict.get("entries", [])
            if not entries:
                logger.warning("æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ¡ç›®")
                return False

            closest_video = None
            closest_time_diff = float("inf")
            oldest_video = None
            oldest_timestamp = float("inf")

            processed_videos_for_closest = []
            if info_dict.get('_type') == 'playlist':
                 for entry_playlist in info_dict.get('entries', []):
                    if entry_playlist and entry_playlist.get('_type') == 'playlist':
                        # ç¡®ä¿ entries ä¸ä¸º None
                        nested_entries = entry_playlist.get('entries') or []
                        for video_in_playlist in nested_entries:
                             if video_in_playlist: processed_videos_for_closest.append(video_in_playlist)
                    elif entry_playlist:
                        processed_videos_for_closest.append(entry_playlist)
            else:
                processed_videos_for_closest = info_dict.get('entries') or []

            for video_data in processed_videos_for_closest:
                video_timestamp = video_data.get("timestamp")
                if not video_timestamp:
                    upload_date = video_data.get("upload_date")
                    if upload_date:
                        try:
                            video_timestamp = int(datetime.datetime.strptime(upload_date, "%Y%m%d").timestamp())
                        except ValueError: continue
                    else: continue

                if video_timestamp < oldest_timestamp:
                    oldest_timestamp = video_timestamp
                    oldest_video = video_data
                if target_timestamp is not None:
                    time_diff = video_timestamp - target_timestamp
                    if 0 < time_diff < closest_time_diff:
                        closest_time_diff = time_diff
                        closest_video = video_data
            
            if target_timestamp is None and oldest_video:
                closest_video = oldest_video
            
            if not closest_video:
                logger.warning("æ ¹æ®æ—¶é—´æˆ³æœªæ‰¾åˆ°åˆé€‚è§†é¢‘")
                return False
            
            video_webpage_url = closest_video.get("webpage_url")
            if not video_webpage_url:
                logger.error(f"é€‰å®šè§†é¢‘æ²¡æœ‰webpage_url: {closest_video.get('title', 'æœªçŸ¥')}")
                return False

            video_id_history = closest_video.get('id', 'unknown_id')
            
            log_with_context(
                logger, logging.INFO,
                "é€‰å®šè¦ä¸‹è½½çš„å†å²è§†é¢‘",
                video_id=video_id_history,
                title=closest_video.get('title', 'æœªçŸ¥æ ‡é¢˜')
            )

            # æ„å»ºæ–‡ä»¶åï¼š{é¢‘é“å}.{video_id}.{title}.m4a
            uploader = closest_video.get('uploader') or closest_video.get('channel') or channel_name or 'UnknownChannel'
            safe_uploader = sanitize_filename(uploader)
            
            fulltitle = closest_video.get('fulltitle') or closest_video.get('title') or 'UnknownTitle'
            safe_title = sanitize_filename(fulltitle)
            expected_audio_ext = ".m4a"
            final_audio_filename_stem = f"{safe_uploader}.{video_id_history}.{safe_title}"

            # ä¸´æ—¶æ–‡ä»¶æ ¼å¼ï¼šfilename.tmp.m4a (yt-dlpä¸‹è½½ä¸ºfilename.tmpï¼ŒFFmpegè½¬æ¢ä¸ºfilename.tmp.m4a)
            temp_audio_path_without_ext = os.path.join(au_folder, final_audio_filename_stem)
            expected_temp_audio_path = temp_audio_path_without_ext + ".tmp" + expected_audio_ext
            final_destination_audio_path = os.path.join(au_folder, f"{final_audio_filename_stem}{expected_audio_ext}")

            if os.path.exists(final_destination_audio_path):
                logger.trace(f"æœ€ç»ˆéŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {final_destination_audio_path}")
                timestamp_to_update = closest_video.get("timestamp", closest_video.get("upload_date"))
                if timestamp_to_update:
                    if isinstance(timestamp_to_update, str):
                         timestamp_to_update = int(datetime.datetime.strptime(timestamp_to_update, "%Y%m%d").timestamp())
                    update_channel_info_file(channel_name, timestamp_to_update, STORY_FILE)
                return True

            single_video_ydl_opts = ydl_opts.copy()
            # FFmpegåå¤„ç†å™¨ä¼šå°† filename.tmp è½¬æ¢ä¸º filename.tmp.m4a
            single_video_ydl_opts['outtmpl'] = temp_audio_path_without_ext + '.tmp'
            single_video_ydl_opts.pop('playlistend', None) 
            single_video_ydl_opts.pop('match_filter', None)

            with yt_dlp.YoutubeDL(single_video_ydl_opts) as single_video_downloader:
                single_video_downloader.download([video_webpage_url])

            if os.path.exists(expected_temp_audio_path):
                logger.info(f"å†å²è§†é¢‘è½¬æ¢åéŸ³é¢‘å·²ä¸‹è½½ï¼ˆä¸´æ—¶æ–‡ä»¶ï¼‰: {expected_temp_audio_path}")
                if safe_rename_file(expected_temp_audio_path, final_destination_audio_path):
                    log_with_context(
                        logger, logging.INFO,
                        "æˆåŠŸé‡å‘½åå†å²è§†é¢‘éŸ³é¢‘",
                        destination=final_destination_audio_path
                    )

                    record_download_entry(video_id_history, channel_name)
                else:
                    logger.error(f"å†å²è§†é¢‘é‡å‘½åå¤±è´¥ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")

                timestamp_to_update = closest_video.get("timestamp", closest_video.get("upload_date"))
                if timestamp_to_update:
                    if isinstance(timestamp_to_update, str):
                         timestamp_to_update = int(datetime.datetime.strptime(timestamp_to_update, "%Y%m%d").timestamp())
                    update_channel_info_file(channel_name, timestamp_to_update, STORY_FILE)
                return True
            else:
                logger.error(f"å†å²è§†é¢‘è½¬æ¢åçš„éŸ³é¢‘æ–‡ä»¶ï¼ˆä¸´æ—¶æ–‡ä»¶ï¼‰æœªæ‰¾åˆ°: {expected_temp_audio_path}")
                return False
            
        except Exception as e:
            log_with_context(
                logger, logging.ERROR,
                "å¤„ç†å†å²è§†é¢‘æ—¶å‘ç”Ÿé”™è¯¯",
                yt_channel=channel_name,
                error=str(e)
            )
            return False


def read_and_process_channels(channels_file_path, au_folder):
    if not os.path.exists(channels_file_path):
        logger.error(f"No channel info file found at {channels_file_path}")
        return

    with open(channels_file_path, "r", encoding="utf-8") as f:
        lines = f.readlines()

    for line in lines:
        parts = line.strip().split()
        channel_name = parts[0]
        timestamp = int(parts[1]) if len(parts) > 1 else None

        log_with_context(
            logger, logging.INFO,
            "Processing channel",
            yt_channel=channel_name,
            timestamp=timestamp
        )
        dl_audio_closest_after(AUDIO_FOLDER, channel_name, timestamp)

# ===== Story download helpers =====

def _extract_timestamp_from_entry(entry: dict) -> Optional[int]:
    """Extract upload timestamp (UTC seconds) from yt-dlp entry."""
    if not entry:
        return None
    ts = entry.get("timestamp")
    if ts is not None:
        return ts
    upload_date = entry.get("upload_date")
    if upload_date:
        try:
            naive = datetime.datetime.strptime(upload_date, "%Y%m%d")
            return int(naive.replace(tzinfo=datetime.timezone.utc).timestamp())
        except Exception:
            return None
    return None


def dl_audio_story(channel_name: str, audio_folder: str, group_name: str, items_per_run: int = 1) -> bool:
    """Download next batch for story-type channels (oldest to newest)."""
    if not check_cookies():
        return False

    target_folder = audio_folder if audio_folder else AUDIO_FOLDER
    os.makedirs(target_folder, exist_ok=True)

    provider = get_config_provider()
    progress: dict = {}
    try:
        progress = provider.get_story_progress(group_name) or {}
    except Exception as err:
        logger.warning(f"è¯»å–æ•…äº‹è¿›åº¦å¤±è´¥: {err}")
        progress = {}

    last_video_id = progress.get("last_video_id")
    last_ts = progress.get("last_timestamp")
    run_started_ts = time.time()

    list_opts = {
        "quiet": True,
        "cookiefile": COOKIES_FILE,
        "playlistreverse": True,
    }
    list_opts = apply_js_runtime(list_opts)

    last_ts_int: Optional[int] = None
    if last_ts is not None:
        try:
            last_ts_int = int(last_ts)
        except (TypeError, ValueError):
            last_ts_int = None

    timestamp_checkpoint_value = last_ts_int if last_ts_int is not None else last_ts

    if last_ts_int is not None:
        try:
            cutoff_dt = datetime.datetime.fromtimestamp(
                last_ts_int, tz=datetime.timezone.utc
            )
            dateafter_value = cutoff_dt.strftime("%Y%m%d")
            list_opts["dateafter"] = dateafter_value
            logger.trace(
                f"ğŸ“š æ•…äº‹é¢‘é“ {group_name} ä½¿ç”¨ dateafter è¿‡æ»¤ï¼š{dateafter_value}"
            )
        except Exception as err:
            logger.trace(
                f"âš ï¸ æ•…äº‹é¢‘é“ {group_name} è®¾ç½® dateafter å¤±è´¥ï¼Œå°†å›é€€åˆ°å®Œæ•´æ‰«æ: {err}"
            )
    selected_entries: list = []
    items_limit = max(1, int(items_per_run or 1))
    channel_url = f"{yt_base_url}{channel_name}/videos"

    try:
        with yt_dlp.YoutubeDL(list_opts) as list_ydl:
            channel_info = list_ydl.extract_info(channel_url, download=False)
    except Exception as err:
        log_with_context(
            logger,
            logging.ERROR,
            "Story mode: failed to fetch channel entries",
            yt_channel=channel_name,
            error=str(err),
        )
        return False

    entries = []
    raw_entries = channel_info.get("entries") if channel_info else None
    if raw_entries is not None:
        for entry in raw_entries:
            if entry and isinstance(entry, dict):
                entries.append(entry)
    else:
        log_with_context(
            logger,
            logging.WARNING,
            "Story mode: channel returned no entries",
            yt_channel=channel_name,
        )

    if entries:
        if last_ts_int is not None:
            for entry in entries:
                entry_ts = _extract_timestamp_from_entry(entry)
                if entry_ts is None:
                    log_with_context(
                        logger,
                        TRACE_LEVEL,
                        "Story mode: skip entry without timestamp while checkpoint is set",
                        yt_channel=channel_name,
                        video_id=entry.get("id"),
                    )
                    continue
                if entry_ts <= last_ts_int:
                    continue
                selected_entries.append(entry)
                if len(selected_entries) >= items_limit:
                    break
        else:
            found_last_id = last_video_id is None
            for entry in entries:
                entry_id = entry.get("id")
                if not found_last_id:
                    if entry_id == last_video_id:
                        found_last_id = True
                    continue
                selected_entries.append(entry)
                if len(selected_entries) >= items_limit:
                    break
            if last_video_id and not found_last_id:
                log_with_context(
                    logger,
                    logging.WARNING,
                    "Story mode: checkpoint video not found, defaulting to earliest entries",
                    yt_channel=channel_name,
                    checkpoint_video=last_video_id,
                )
                selected_entries = entries[:items_limit]
    else:
        log_with_context(
            logger,
            logging.INFO,
            "Story mode: no valid entries returned by channel",
            yt_channel=channel_name,
        )

    if not selected_entries:
        log_with_context(
            logger,
            logging.INFO,
            "Story mode: no pending entries to download",
            yt_channel=channel_name,
            last_timestamp=timestamp_checkpoint_value,
            last_video_id=last_video_id,
        )

    last_progress_id = None
    last_progress_ts = None
    downloaded = 0

    for entry in selected_entries:
        video_id = entry.get("id") or ""
        if not video_id:
            continue
        video_url = entry.get("webpage_url") or entry.get("url") or f"{yt_base_url}watch?v={video_id}"

        # å‡†å¤‡ä¸€ä¸ªå®¹å™¨æ¥æ¥çœŸå®æ–‡ä»¶å
        downloaded_file_info = {"path": None}

        def story_progress_hook(d):
            if d['status'] == 'finished':
                # è·å–çœŸå®çš„æ–‡ä»¶è·¯å¾„
                downloaded_file_info["path"] = d.get('filename')

        uploader = entry.get("uploader") or entry.get("channel") or channel_name or "UnknownChannel"
        safe_uploader = sanitize_filename(uploader)
        title = entry.get("fulltitle") or entry.get("title") or video_id
        safe_title = sanitize_filename(title)
        ts = _extract_timestamp_from_entry(entry)

        final_stem = f"{safe_uploader}.{video_id}.{safe_title}"
        expected_audio_ext = ".m4a"
        final_destination_audio_path = os.path.join(target_folder, f"{final_stem}{expected_audio_ext}")

        last_progress_id = video_id
        last_progress_ts = ts

        # åŒä¸€æ‰¹æ•…äº‹æ¡ç›®ä¹‹é—´å¢åŠ è§†é¢‘çº§å»¶è¿Ÿï¼Œé™ä½è¯·æ±‚é¢‘ç‡
        if downloaded > 0:
            v_delay_min = get_video_delay_min()
            v_delay_max = get_video_delay_max()
            if v_delay_max > 0 and v_delay_max >= v_delay_min:
                delay = random.uniform(v_delay_min, v_delay_max)
                log_with_context(
                    logger,
                    logging.INFO,
                    "æ•…äº‹æ¡ç›®é—´å»¶è¿Ÿ",
                    yt_channel=channel_name,
                    delay_seconds=round(delay, 2)
                )
                time.sleep(delay)

        if os.path.exists(final_destination_audio_path):
            log_with_context(
                logger, logging.INFO,
                "æ•…äº‹è§†é¢‘å·²å­˜åœ¨",
                yt_channel=channel_name,
                video_id=video_id
            )
            continue

        custom_opts = {
            "match_filter": member_content_filter,
            "keepvideo": False,
            "outtmpl": os.path.join(target_folder, f"%(uploader)s.%(id)s.%(title)s.tmp"),
            "progress_hooks": [story_progress_hook],
        }
        ydl_opts = get_ydl_opts(custom_opts)

        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([video_url])
        except yt_dlp.utils.DownloadError as de:
            logger.error(f"æ•…äº‹è§†é¢‘ä¸‹è½½é”™è¯¯: {de}")
            continue
        except Exception as e:
            logger.error(f"æ•…äº‹è§†é¢‘ä¸‹è½½å¼‚å¸¸: {e}")
            continue

        # ä½¿ç”¨ Hook æ•è·çš„çœŸå®è·¯å¾„
        hook_reported_temp_path = downloaded_file_info.get("path")
        actual_temp_path = hook_reported_temp_path
        resolved_temp_path = None

        candidate_paths = []
        if actual_temp_path:
            candidate_paths.append(actual_temp_path)
            parent_dir, temp_filename = os.path.split(actual_temp_path)
            if ".tmp.f" in temp_filename:
                normalized_filename = re.sub(r"(\.tmp)\.f\d+(?=\.)", r"\1", temp_filename)
                candidate_paths.append(os.path.join(parent_dir, normalized_filename))

        for candidate in candidate_paths:
            if candidate and os.path.exists(candidate):
                resolved_temp_path = candidate
                break

        # å¦‚æœ Hook æ²¡æ‹¿åˆ°ï¼Œå°è¯•æ¨¡ç³ŠæŸ¥æ‰¾
        if not resolved_temp_path:
            for f in os.listdir(target_folder):
                if video_id in f and (f.endswith('.tmp.m4a') or f.endswith('.tmp')):
                    resolved_temp_path = os.path.join(target_folder, f)
                    break

        actual_temp_path = resolved_temp_path

        if actual_temp_path and os.path.exists(actual_temp_path):
            if safe_rename_file(actual_temp_path, final_destination_audio_path):
                file_size_mb = os.path.getsize(final_destination_audio_path) / (1024 * 1024)
                log_with_context(
                    logger, logging.INFO,
                    "æ•…äº‹è§†é¢‘ä¸‹è½½æˆåŠŸ",
                    yt_channel=channel_name,
                    video_id=video_id,
                    size_mb=round(file_size_mb, 2)
                )
                downloaded += 1
                record_download_entry(video_id, channel_name)
            else:
                logger.error(f"æ•…äº‹è§†é¢‘é‡å‘½åå¤±è´¥: {actual_temp_path}")
        else:
            logger.error(f"æœªæ‰¾åˆ°é¢„æœŸçš„ä¸´æ—¶æ–‡ä»¶ (hook path: {hook_reported_temp_path})")

    if last_progress_id:
        provider.update_story_progress(group_name, {
            "last_video_id": last_progress_id,
            "last_timestamp": last_progress_ts,
            "last_run_ts": int(run_started_ts)
        })
    else:
        provider.update_story_progress(group_name, {"last_run_ts": int(run_started_ts)})

    return downloaded > 0
